# 网易公开课——清华大学公开课：操作系统

#### 共98集

---

## 3.1计算机体系结构及内存分层体系

+ 计算机体系结构/内存分层体系
+ 地址空间 & 地址生成
+ 连续内存分配

---

#### 计算机体系结构/内存分层体系

计算机基本硬件结构：CPU、内存、设备I/O

#### 内存的层次结构

CPU可以访问的数据包括：
寄存器、cache：CPU芯片内部，速度很快，容量很小

主存或者物理内存：放置OS、代码等，容量大很多，速度相对慢

磁盘（虚拟内存）：速度慢很多，容量大很多，5ms寻道时间

#### 操作系统在内存管理的任务

+ 抽象：逻辑地址空间
+ 保护：独立地址空间
+ 共享：访问相同内存
+ 虚拟化：更多的地址空间

---

# 磁盘是虚拟内存，磁盘和主存是物理地址空间，程序使用的是逻辑地址空间

# 虚拟内存和虚拟地址空间是两回事

---

#### 在操作系统中管理内存的不同方法

+ 程序重定位
+ 分段
+ 分页
+ 虚拟内存
+ 按需分页虚拟内存

#### 实现高度依赖于硬件

+ 必须知道内存架构
+ MMU（内存管理单元）：硬件组件负责处理CPU的内存访问请求

---

## 3.2地址空间与地址生成

+ 地址空间定义
+ 地址生成
+ 地址安全检查

---

#### 物理地址空间——硬件支持的地址空间

起始地址0到地址MAXsys，管理和控制由硬件来完成

#### 逻辑地址空间——一个运行的程序所拥有的内存范围

起始地址0到地址MAXprog，操作系统管理映射关系，协调

#### 逻辑地址生成过程

汇编程序汇编器后，.o文件中符号转换成从0开始的连续地址空间，这是逻辑地址空间
linker工具将多个.o程序变成单一的.exe文件，硬盘中
loader应用程序把.exe从磁盘载入内存运行。程序重定位，内存地址完成分配，地址有一定的偏移量

#### 硬件的MMU

有一块区域表示映射关系，内存中也有：完成了逻辑地址到物理地址的映射

#### 过程

1. CPU运算器需要在逻辑地址的内存内容
2. 内存管理单元寻找在逻辑地址和物理地址之间的映射
3. 控制器从总线发送在物理地址的内存内容的请求
4. 内存发送物理地址内存的内容给CPU

#### 操作系统的任务：建立物理地址和逻辑地址之间的映射关系，这个关系可以放在内存中，由CPU进行缓存加速

#### 确保程序之间不相互干扰，限制和约束，地址安全检测

操作系统方面：设置逻辑地址空间的==基址==和==界限==

---

## 3.3连续内存分配：内存碎片与分区的动态分配

#### 连续内存分配

+ 内存碎片问题
+ 分区的动态分配
  + 第一适配
  + 最佳适配
  + 最差适配
+ 压缩式碎片整理
+ 交换式碎片整理

---

#### 内存碎片问题

+ 空闲内存不能被利用
+ 外部碎片：在分配单元间的未使用内存
+ 内部碎片：在分配单元中的未使用内存

#### 分区的动态分配

简单的内存管理方法

+ 当一个程序准许运行在内存中时，分配一个连续的区间
+ 分配一个连续的内存区间给运行的程序以访问数据

操作系统进行跟踪哪些被使用哪些空闲：满块、空块（“孔洞”）

#### 分配策略

+ 首次适配：为了分配n字节，使用第一个可用空闲块，以致块的尺寸比n大
+ 最优适配：为了分配n字节，使用最小的可用空闲块，以致块的尺寸比n大
+ 最差适配：为了分配n字节，使用最大的可用空闲块，以致块的尺寸比n大

#### 没有最好的策略，应用程序的需求是随机的。==实际中使用的是更复杂的算法==

---

#### 首次适配

基本原理&实现

+ 简单实现
+ 需求：
  按地址排序的空闲块列表
  分配需要寻找一个合适的分区
  重分配需要检查，看是否自由分区能合并于相邻的空闲分区（若有），==困难==
+ 优势
  + 简单
  + 易于产生更大空闲块，向着地址空间的结尾
+ 劣势
  + 外部碎片
  + 不确定性

---

#### 最优适配

基本原理&实现

+ 为了避免分割大空闲块
+ 为了最小化外部碎片产生的尺寸
+ 需求：
  按尺寸排列的空闲块列表
  分配需要寻找一个合适的分区
  重分配需要搜索及合并于相邻的空闲分区，若有，==困难==
+ 优势
  + 当大部分分配是小尺寸时非常有效
  + 比较简单
+ 劣势
  + 外部碎片
  + 重分配慢
  + 易产生很多没用的微小碎片（不怎么好）

---

#### 最差适配

基本原理&实现

+ 为了避免有太多微小的碎片
+ 需求：
  按尺寸排列的空闲块列表
  分配很快（获得最大的分区）
  重分配需要合并于相邻的空闲分区，若有，然后调整空闲块列表
+ 优势
  + 假如分配是中等尺寸效果最好
+ 劣势
  + 重分配慢
  + 外部碎片
  + 易于破碎大的空闲块以致大分区无法被分配

---

## 3.4连续内存分配：压缩式与交换式碎片整理

#### 压缩式碎片整理：

+ 重置程序以合并孔洞
+ 要求所有程序是动态可置的
+ 议题：
  + 何时重置
  + 开销（软件执行，开销大）

#### 交换式碎片整理：

+ 运行程序需要更多的内存
+ 抢占等待的程序 & 回收它们的内存
+ 问题：哪些程序交换

---





---

## 4.1非连续内存分配：分段==（用得少）==

+ 非连续内存分配
+ 为什么需要非连续内存分配
+ 分段Segmentation
+ 分页Paging
+ 页表Page Table

---

#### 连续内存分配的缺点

+ 分配给一个程序的物理内存是连续的
+ 内存利用率较低
+ 由外碎片、内碎片的问题

#### 非连续分配的优点

+ 一个程序的物理地址空间是非连续的
+ 更好的内存利用和管理
+ 允许共享代码与数据（共享库等...）
+ 支持动态加载和动态链接

#### 非连续分配的缺点

+ 如何建立虚拟地址和物理的地址之间的转换==（管理开销本身）==
  + 软件方案，开销大
  + 硬件方案
+ 两种硬件方案
  + 分段
  + 分页

---

#### 分段

+ 程序的分段地址空间
+ 分段寻址方案

更好的分离和共享

---

#### 硬件来实现

分段寻址方案

#### 段访问机制：

+ 新概念：一个段：一个内存“块”
  + 一个逻辑地址空间
+ 程序访问内存地址需要：一个2维的二元组(s, addr)
  + s——段号
  + addr——段内偏移
+ 段寄存器+地址寄存器实现方案（如x86）
+ 单地址实现方案

---

#### 硬件机制：

+ 段表：逻辑地址的段号和物理地址的段号的对应关系；段起始地址，段长度限制

段表由操作系统建立，和硬件紧密联系

---

## 4.2非连续内存分配：分页

+ 分页地址空间
+ 页寻址方案

---

分段和分页的区别：分段的段大小是不固定的，分页的页大小是固定的

#### 划分物理内存至固定大小的帧

+ 大小是2的幂，512，4096，8192字节

#### 划分逻辑地址空间至相同大小的页（便于硬件实现）

+ 大小是2的幂，512，4096，8192字节

frame是物理页，page是逻辑页

#### 建立方案，转换逻辑地址为物理地址pages to frames

+ 页表
+ MMU/TLB

---

#### Frame帧

+ 物理内存被分割为大小相等的帧
+ 一个内存物理地址是一个二元组(f, o)
  + f——帧号（F位，共有2^F个帧）
  + o——帧内偏移（S位，每帧有2^S字节）
  + 物理地址 = 2^S x f + o
+ 例如：16-bit的地址空间，9-bit（512byte）大小的页帧，物理地址（3,6）表示地址为1542
  + 2^S x f + o = 2^9 x 3 + 6 = 1542

---

#### Page页

+ 和帧计算方法一样
+ 一个程序的逻辑地址空间被划分为大小相等的页
  + 页内偏移的大小 = 帧内偏移的大小
  + ==页号大小<>帧号大小==
+ 一个逻辑地址是一个二元组(p, o)
  + p——页号（P位，2^P个页）
  + o——页内偏移（S位，每页有2^S字节）
  + 虚拟地址 = 2^S x p + o

---

#### 页寻址机制

页表保存了逻辑地址——物理地址之间的映射关系。由操作系统建立，初始化操作系统时建立

逻辑地址——页表——物理地址

+ 页映射到帧
+ 页是连续的虚拟内存
+ 帧是非连续的物理内存
+ 不是所有的页都有对应的帧

---

## 4.3非连续内存分配：页表-概述、TLB

+ 页表
  + 页表概述
  + 转换后备缓冲区TLB
  + 二级/多级页表
  + 反向页表
+ 页表的实现是操作系统和硬件共同配合的结果

---

#### 页表结构

每个运行的程序都有一个页表

+ 属于程序运行状态，会动态变化
+ PTBR：页表基址寄存器
+ 页表项的内容：
  + Flags(标志位)
    + dirty bit
    + resident bit驻留位：物理页帧是否存在，1存在；0不存在，出现内存访问异常
    + clock/reference bit
  + 帧号：f

---

#### 分页机制的性能问题

空间代价和时间开销问题

#### 问题：访问一个内存单元需要2次内存访问

+ 一次用于获取页表项
+ 一次用于访问数据

#### 页表可能非常大

+ 64位机器如果每页1024字节，那么一个页表的大小会是2^54，计算机无法存储
+ n个程序n个页表
+ 大到一定程度不能放入cache（最大也就几兆），需要放入内存

#### 如何处理？==大多数计算机问题解决方案==

+ 缓存Caching：常用内容缓存
+ 间接Indirection访问：大空间拆成小空间，多级页表机制等

---

#### TLB Translation Look-aside Buffer

在MMU中，是一个缓冲，缓冲页表的内容

+ 缓存近期访问的页帧转换表项
  + TLB使用associative memory（关联内存，容量有限）实现，具备快速访问性能
  + 如果TLB命中，物理页号可以很快被获取
  + 如何TLB未命中，对应的表项被更新到TLB中

+ 首先根据P，查询TLB
+ TLB miss时，CPU不得不去查页表，然后将查到的放入TLB，x86CPU由硬件完成，其他CPU可能由OS完成
+ TLB的机制使得TLB miss很小，可以通过编程的方式对内存访问集中在一个区域，访问的局部性

---

## 4.4非连续内存分配：页表-二级、多级页表

#### 二级页表p1, p2, o

一级页表存储二级页表的基址
某些映射关系不存在的二级页表可以不存在，极大节省空间

#### 多级页表

通过把页号分为k个部分，来实现多级间接页表
时间换空间
建立页表“树”

---

## 4.5非连续内存分配：页表-反向页表

#### 非连续内存分配：

+ 为什么需要非连续内存分配
+ 分段Segmentation
+ 分页Paging
+ 页表Page Table
  + 页表概览
  + 快表Translation Look-aside Buffer TLB
  + 二级、多级页表
  + 反向页表inverted page table

---

#### 大地址空间问题

+ 有大地址空间64-bits，前向映射页表变得==繁琐==
  + 比如：5级页表
+ 不是让页表与逻辑地址空间的大小相对应，而是让页表与物理地址空间的大小相对应
  + 逻辑（虚拟）地址空间增长速度快于物理地址空间

---

#### 1.基于页寄存器（Page Registers）的方案

帧号f为index，页号P为表项内容

+ 每个帧和一个寄存器关联，寄存器内容包括：
  + Residence bit：此帧是否被占用
  + Occupier：对应的页号p
  + Protection bits：保护位
+ 页寄存器：一个例子
  + 物理内存大小：4096x4096 = 4K x 4KB = 16MB
  + 页面大小：4096 bytes = 4KB
  + 页帧数：4096 = 4K
  + 页寄存器使用的空间（假设8bytes/register）：
    + 8 x 4096 = 32Kbytes
  + 页寄存器带来的额外开销：
    + 32K / 16M = 0.2%（大约）==所占空间极小==
  + 虚拟内存的大小：任意
+ 如何建立映射关系：页号 ----> 帧号

#### 页寄存器方案的权衡

+ 利
  + 转换表的大小相对于物理内存来说很小
  + 转换表的大小跟逻辑地址空间的大小无关
+ 弊
  + 需要的信息对调了，即根据帧号可找到也页号
  + 如何转换回来？即根据页号找到帧号
  + 在需要在反向页表中搜索想要的页号

---

#### 2.基于关联内存（associative memory）的方案

特殊的存储器，并行的查找页号对应的帧号
设计成本太大，技术复杂，容量有限，16M大小开销极大

#### 在反向页表中搜索一个页对应的帧号

+ 如果帧数较少，页寄存器可以被放置在关联内存中
+ 在关联内存中查找逻辑页号
  + 成功：帧号被提取
  + 失败：页错误异常page fault
+ 限制因素：
  + 大量的关联内存非常昂贵
    + 难以在单个时钟周期内完成
    + 耗电

---

#### 3.基于哈希hash查找的方案

哈希函数可以硬件加速，为提高效率，还引入参数PID，当前运行程序标识

帧号f = h(PID, p)

#### 在反向页表中通过哈希算法来搜索一个页对应的帧号

+ 对页号做哈希计算，为了在“帧表”（每帧拥有一个表项）中获取对应的帧号
+ 页i被放置在表中f(i)位置，其中f是设定的哈希函数
+ 为了查找页i，执行下列操作：
  + 计算哈希函数f(i)并且使用它作为页寄存器表的索引
  + 获取对应的页寄存器
  + 检查寄存器标签是否包含i，如果包含，则代表成功
  + 否则失败

---

## 5.1









